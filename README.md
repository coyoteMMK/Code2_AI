# CODE2_AI ‚Äî Traductor NL ‚Üí CODE-2 (T5 fine-tuning + ONNX INT8)

Este repositorio contiene el pipeline completo para entrenar y evaluar un modelo tipo T5 que traduce **lenguaje natural (NL)** a **ensamblador CODE-2**.

Incluye:
- Entrenamiento **Full Fine-Tuning** (PyTorch FP32)
- Exportaci√≥n y cuantizaci√≥n **ONNX INT8 din√°mico**
- Evaluaci√≥n con m√©tricas (Exact Match, BLEU, ROUGE-L, tiempo de inferencia)
- Demo local (Gradio) para probar el modelo

---

## üìÅ Estructura del repositorio


CODE2_AI/
‚îú‚îÄ datasource/
‚îÇ  ‚îú‚îÄ train.json
‚îÇ  ‚îú‚îÄ valid.json
‚îÇ  ‚îî‚îÄ test.json
‚îÇ
‚îú‚îÄ models/
‚îÇ  ‚îú‚îÄ full_fp32/           # modelo PyTorch (fine-tuning completo)
‚îÇ  ‚îî‚îÄ onnx_int8_dynamic/   # modelo ONNX cuantizado INT8 din√°mico
‚îÇ
‚îú‚îÄ scripts/
‚îÇ  ‚îú‚îÄ training.py
‚îÇ  ‚îú‚îÄ evaluate.py
‚îÇ  ‚îú‚îÄ quantize_onnx_int8_dynamic.py
‚îÇ  ‚îú‚îÄ showcase.py
‚îÇ  ‚îú‚îÄ data-generation.py
‚îÇ  ‚îî‚îÄ test_env.py
‚îÇ
‚îú‚îÄ README.md
‚îî‚îÄ requirements.txt

---

## ‚úÖ Instalaci√≥n

Se recomienda entorno virtual:

```bash
python -m venv .venv
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate
````

Instalaci√≥n de dependencias:

```bash
pip install -r requirements.txt
```

---

## üèãÔ∏è Entrenamiento (Full Fine-Tuning)

Entrena un modelo y lo guarda en `models/full_fp32/`.

```bash
python scripts/training.py \
  --model_name t5-small \
  --train_json datasource/train.json \
  --valid_json datasource/valid.json \
  --save_dir models/full_fp32
```

> Para continuar entrenando desde un modelo ya afinado (no desde `t5-small`), usa:

```bash
python scripts/training.py \
  --model_name models/full_fp32 \
  --train_json datasource/train.json \
  --valid_json datasource/valid.json \
  --save_dir models/full_fp32
```

---

## ‚öôÔ∏è Cuantizaci√≥n ONNX INT8 (PTQ din√°mico)

Exporta a ONNX y aplica cuantizaci√≥n INT8 din√°mica. Guarda el resultado en `models/onnx_int8_dynamic/`.

```bash
python scripts/quantize_onnx_int8_dynamic.py \
  --model_dir models/full_fp32 \
  --out_dir models/onnx_int8_dynamic
```

---

## üìä Evaluaci√≥n

Eval√∫a **dos modelos**:

* `models/full_fp32/` (PyTorch FP32)
* `models/onnx_int8_dynamic/` (ONNX INT8 din√°mico)

```bash
python scripts/evaluate.py \
  --fp32_dir models/full_fp32 \
  --onnx_dir models/onnx_int8_dynamic \
  --valid_json datasource/valid.json \
  --n 2000
```

M√©tricas calculadas:

* Exact Match (con normalizaci√≥n de espacios y saltos de l√≠nea)
* BLEU
* ROUGE-L
* Tiempo medio de inferencia
* Longitud media en tokens

---

## üß™ Demo local (Gradio)

Lanza una app local para introducir instrucciones multil√≠nea y elegir modelo (FP32 u ONNX INT8).

```bash
python scripts/showcase.py
```

---

## üß† Formato esperado

### Entrada (NL)

* Texto multil√≠nea (una instrucci√≥n por l√≠nea)
* Se permite variaci√≥n de may√∫sculas/min√∫sculas

Ejemplo:

```text
Suma r1 y r2 y guarda en r3
Guarda r3 en la direcci√≥n 0345
```

### Salida (CODE-2)

Ejemplo:

```text
ADDS r3,r1,r2
ST [rD+H'45'],r3 ; rD = 0300
```

---

## üìå Notas de compatibilidad

* `transformers` requiere `huggingface-hub<1.0`.
  Si al instalar aparece `huggingface-hub==1.x`, desinstala y vuelve a instalar:

```bash
pip uninstall -y huggingface-hub
pip install "huggingface-hub<1.0"
```

---

## üìú Licencia

Placeholder (pendiente de definir).

```

---

Si quieres, en el siguiente paso te dejo **el contenido recomendado de cada script** (`evaluate.py`, `quantize_onnx_int8_dynamic.py`, `showcase.py`) con rutas ya alineadas a tu repo (`datasource/` y `models/`).
```
