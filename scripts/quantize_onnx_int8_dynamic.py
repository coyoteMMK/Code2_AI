# scripts/quantize_onnx_int8_dynamic.py
import argparse
import os
from optimum.onnxruntime import ORTModelForSeq2SeqLM
from transformers import T5Tokenizer

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--model_dir", default="models/full_fp32")
    ap.add_argument("--out_onnx_fp32", default="models/onnx_fp32")
    ap.add_argument("--out_onnx_int8", default="models/onnx_int8_dynamic")
    args = ap.parse_args()

    os.makedirs(args.out_onnx_fp32, exist_ok=True)
    os.makedirs(args.out_onnx_int8, exist_ok=True)

    print("üß† Exportando Transformers -> ONNX (FP32) con Optimum...")
    ort_model = ORTModelForSeq2SeqLM.from_pretrained(args.model_dir, export=True)
    ort_model.save_pretrained(args.out_onnx_fp32)

    tokenizer = T5Tokenizer.from_pretrained(args.model_dir)
    tokenizer.save_pretrained(args.out_onnx_fp32)

    print(f"‚úÖ ONNX FP32 guardado en: {args.out_onnx_fp32}")
    print("‚öôÔ∏è Cuantizando ONNX din√°mico INT8...")

    # cuantizaci√≥n ONNX (dynamic) se suele hacer fuera con onnxruntime-tools
    # pero optimum ya deja el modelo listo para ORT; si ya has cuantizado con tu script,
    # aqu√≠ dejamos placeholder "copiar carpeta" o cuantizar con onnxruntime.quantization

    print("‚ÑπÔ∏è Nota: la cuantizaci√≥n ONNX INT8 din√°mico depende de onnxruntime.quantization.")
    print("üëâ Si ya tienes tu carpeta t5_onnx_int8_dynamic, col√≥cala en", args.out_onnx_int8)
    print(f"‚úÖ Listo (placeholder): {args.out_onnx_int8}")

if __name__ == "__main__":
    main()
